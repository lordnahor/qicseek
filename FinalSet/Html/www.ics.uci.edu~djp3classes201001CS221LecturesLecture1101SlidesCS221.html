<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>
<head>
    <meta name="description" content="Matrix Decomposition and Latent Semantic Indexing (LSI) Introduction to Information Retrieval CS 221 Donald J. Patterson  Outline Latent Semantic Indexing Introduction Linear Algebra Refresher  Star Cluster NGC 290 - ESA &amp; NASA Latent Semantic Indexing - Introduction  Star Cluster NGC 290 - ESA &amp; NASA Latent Semantic Indexing - Introduction A picture of the sky is two dimensional The stars are not in two dimensions When we take a photo of stars we are projecting them into 2-D projecting can be defined mathematically When we see two stars that are close.. They may not be close in space When we see two stars that appear far... They may not be far in 3-D space  Star Cluster NGC 290 - ESA &amp; NASA Latent Semantic Indexing - Introduction When we see two stars that are close in a photo They really are close for some applications For example pointing a big telescope at them Large shared telescopes order their views according to how “close” they are.    Overhead projector example Latent Semantic Indexing - Introduction  Overhead projector example Latent Semantic Indexing - Introduction Depending on where we put the light (and the wall) we can make things in three dimensions appear close or far away in two dimensions. Even though the “real” position of the 3-d objects never moved.  Mathematically speaking Latent Semantic Indexing - Introduction This is taking a 3-D point and projecting it into 2-D       The arrow in this picture acts like the overhead projector  Mathematically speaking Latent Semantic Indexing - Introduction We can project from any number of dimensions into any other number of dimensions. Increasing dimensions adds redundant information But sometimes useful Support Vector Machines (kernel methods) do this effectively Latent Semantic Indexing always reduces the number of dimensions  Mathematically speaking Latent Semantic Indexing - Introduction Latent Semantic Indexing always reduces the number of dimensions  Mathematically speaking Latent Semantic Indexing - Introduction Latent Semantic Indexing can project on an arbitrary axis, not just a principal axis  Mathematically speaking Latent Semantic Indexing - Introduction Our documents were just points in an N-dimensional term space We can project them also  Mathematically speaking Latent Semantic Indexing - Introduction Latent Semantic Indexing makes the claim that these new axes represent semantics - deeper meaning than just a term  Mathematically speaking Latent Semantic Indexing - Introduction A term vector that is projected on new vectors may uncover deeper meanings For example Transforming the 3 axes of a term matrix from “ball” “bat” and “cave” to An axis that merges “ball” and “bat” An axis that merges “bat” and “cave” Should be able to separate differences in meaning of the term “bat” Bonus: less dimensions is faster  Linear Algebra Refresher Latent Semantic Indexing - Linear Algebra Refresher Let C be an M by N matrix with real-valued entries for example our term document matrix A matrix with the same number of rows and columns is called a square matrix An M by M matrix with elements only on the diagonal is called a diagonal matrix  The identity matrix is a diagonal matrix with ones on the main diagonal  Matrix Decomposition Latent Semantic Indexing - Linear Algebra Refresher Singular Value Decomposition Splits a matrix into three matrices Such that If  then and and also Sigma is almost a diagonal matrix  Matrix Decomposition Latent Semantic Indexing - Linear Algebra Refresher  Matrix Decomposition Latent Semantic Indexing - Linear Algebra Refresher Singular Value Decomposition Is a technique that splits a matrix into three components with these properties. They also have some other properties which are relevant to latent semantic indexing  Matrix Decomposition Latent Semantic Indexing - Linear Algebra Refresher Singular Value Decomposition Is a technique that splits a matrix into three components with these properties.  Matrix Decomposition Latent Semantic Indexing - Linear Algebra Refresher Singular Value Decomposition SVD enables lossy compression of your term-document matrix reduces the dimensionality or the rank you can arbitrarily reduce the dimensionality by putting zeros in the bottom right of sigma this is a mathematically optimal way of reducing dimensions  Matrix Decomposition Latent Semantic Indexing - Linear Algebra Refresher Singular Value Decomposition If the old dimensions were based on terms  after reducing the rank of the matrix the dimensionality is based on concepts or semantics a concept is a linear combination of terms  Matrix Decomposition Latent Semantic Indexing - Linear Algebra Refresher Singular Value Decomposition    4 dimensions to 3 dimensions  Matrix Decomposition Latent Semantic Indexing - Linear Algebra Refresher Singular Value Decomposition    4 dimensions to 3 dimensions  Matrix Decomposition Latent Semantic Indexing - Linear Algebra Refresher Singular Value Decomposition  Matrix Decomposition Latent Semantic Indexing - Linear Algebra Refresher Singular Value Decomposition  Matrix Decomposition Latent Semantic Indexing - Linear Algebra Refresher Singular Value Decomposition  Matrix Decomposition Latent Semantic Indexing - Linear Algebra Refresher Singular Value Decomposition  Matrix Decomposition Latent Semantic Indexing - Linear Algebra Refresher Singular Value Decomposition  Matrix Decomposition Latent Semantic Indexing - Linear Algebra Refresher Singular Value Decomposition SVD is an algorithm that gives us  With these quantities we can reduce dimensionality With reduced dimensionality synonyms are mapped onto the same location “bat” “chiroptera” polysemies are mapped onto different locations “bat” (baseball) vs. “bat” (small furry mammal)   Latent Semantic Indexing - Linear Algebra Refresher Computing SVD takes a significant amount of CPU It is possible to add documents to a corpus without recalculating SVD The result becomes an approximation To get mathematical guarantees the whole SVD needs to be computed from scratch LSI doesn’t support negation queries LSI doesn’t support boolean queries  Matrix Decomposition Latent Semantic Indexing - Linear Algebra Refresher “I am not crazy” Netflix  Matrix Decomposition Latent Semantic Indexing - Linear Algebra Refresher “I am not crazy” Netflix Machine translations Just like “bat” and “chiroptera” map the same “bat” and “murciélago” can map to the same thing next..."/>
    <title></title>
    <script type="text/javascript" language="javascript">
//      <![CDATA[
            var images = new Array (33);
            images[0] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.001.png";
            images[1] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.002.png";
            images[2] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.003.png";
            images[3] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.004.png";
            images[4] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.005.png";
            images[5] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.006.png";
            images[6] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.007.png";
            images[7] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.008.png";
            images[8] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.009.png";
            images[9] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.010.png";
            images[10] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.011.png";
            images[11] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.012.png";
            images[12] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.013.png";
            images[13] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.014.png";
            images[14] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.015.png";
            images[15] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.016.png";
            images[16] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.017.png";
            images[17] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.018.png";
            images[18] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.019.png";
            images[19] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.020.png";
            images[20] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.021.png";
            images[21] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.022.png";
            images[22] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.023.png";
            images[23] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.024.png";
            images[24] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.025.png";
            images[25] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.026.png";
            images[26] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.027.png";
            images[27] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.028.png";
            images[28] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.029.png";
            images[29] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.030.png";
            images[30] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.031.png";
            images[31] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.032.png";
            images[32] = "Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.033.png";
            var index = 0;
            function WindowLoaded(evt)
            {
                document.body.onselectstart = function () { return false; };
            }
            function Step(i)
            {
                GoTo(index + i)
            }
            function GoTo(newIndex)
            {
                if(newIndex >= 0 && newIndex < images.length)
                {
                    index = newIndex;
                    document.Slideshow.src = images[index];
                }
            }
//      ]]>
    </script>
</head>
<body bgcolor="black" onload='WindowLoaded(event);'>
    <p align="center">
        <br/>
        <br/>
        <img name="Slideshow" alt="" src="Lecture11_01_Slides_CS221_files/Lecture11_01_Slides_CS221.001.png" onclick="Step(1)"/>
        <br/>
        <br/>
        <input type="image" src="Lecture11_01_Slides_CS221_files/home.png" onclick="GoTo(0)"/>
        &nbsp;&nbsp;&nbsp;
        <input type="image" src="Lecture11_01_Slides_CS221_files/prev.png" onclick="Step(-1)"/>
        <input type="image" src="Lecture11_01_Slides_CS221_files/next.png" onclick="Step(1)"/>
    </p>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
var pageTracker = _gat._getTracker("UA-15170336-1");
pageTracker._trackPageview();
} catch(err) {}</script>

</body>
</html>

