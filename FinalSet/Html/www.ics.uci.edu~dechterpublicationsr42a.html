<html>
    <head>
      <title>
        Dr. Rina Dechter @ UCI
      </title>
      <LINK REL="Stylesheet" HREF="/~dechter/basic.css">		
    </HEAD>
  
  <BODY bgcolor="#ffffff" alink="00aaaa" link="008080" vlink="008080">
  
  <!-- Begin Header -->
    <center>
<table width="95%" cellspacing="0" cellpadding="0" border="0">
  <tr>
    <td class="title" valign="bottom">
      <nobr>Dr. Rina Dechter - University of California at Irvine</nobr></td>

    <td><img alt="ZOT!" align="right" valign="bottom" src="/~dechter/images/anteater-ics.gif"></td>
  </tr>

  <tr>
    <td colspan="2"><img height="2" src="/~dechter/images/transp-fill.gif"></td>
  </tr>

  <tr>
    <td colspan="2"><img width="100%" height="2"  src="/~dechter/images/black-fill.gif"></td>
  </tr>

  <tr valign=top>
    <td><font color="ffaa00" size="3"><a href="/~dechter/index.html">home</a> |
    <a href="/~dechter/publications.html">publications</a> |
    <a href="/~dechter/books/">book</a> |
		<a href="/~dechter/courses.html">courses</a> |
    <a href="/~dechter/research.html">research</a></font></td>
    <td align=right><font color=#008080>Revised on
      
      Jul. 22, 2013</font></td>
  </tr>
</table>
</center>
  <!-- End Header -->
  
  
  <!-- Begin Body -->
  
  <br><br><center>
<table width=90%>
<tr>
<td class=title>Publications & Technical Reports</td>
<tr>
  <td colspan=2><img width="100%" height="2"  src="/~dechter/images/black-fill.gif"></td>
</tr>
</tr>
</table>
</center> 
<center>
<table width="80%" cellspacing="0" cellpadding="0" border="0">
<tr valign=top>
<td><b>R42a</td>
 | 
<br></td>
</tr>

<tr>
<td colspan=2><div class=title>Value Iteration And Policy Iteration Algorithms For Markov Decision Problem</div>
<tt>
Elena Pashenkova, Irina Rish (<A href="mailto:irinar@ics.uci.edu">irinar@ics.uci.edu</A>) &
Rina Dechter (<A href="mailto:dechter@ics.uci.edu">dechter@ics.uci.edu</A>)
</tt></td></tr>
</table>

<table width="80%" cellspacing="0" cellpadding="0" border="0">
<tr><td>
<br><div class=abstract>
<b>Abstract</b><BR>
In this paper we consider computational aspects of decision-theoretic planning
modeled by Markov decision processes (MDPs). Commonly used algorithms, such as 
value iteration (VI) [Bellman, 1957] and several versions of modified policy 
iteration (MPI) [Puterman, 1994] (a modification of the original Howard's policy
iteration (PI) [Howard, 1960]), are compared on a class of problems from the motion 
planning domain. Policy iteration and its modifications are usually recommended 
as algorithms demonstrating a better performance than value iteration
[Russel & Norvig, 1995], [Puterman, 1994]. However, our results show that their
performance is not always superior and depends on the parameters of a problem
and the parameters of the algorithms, such as number of iterations in the value determination 
procedure in MPI. Moreover, policy iteration applied to non-discounted
models without special restrictions might not even converge to an optimal policy, as
in case of the policy iteration algorithm introduced in [Russel & Norvig, 1995]. We
also introduce a new stopping criterion into value iteration based on policy changes.
The combined value-policy iteration (CVPI) algorithm proposed in the paper implements 
this criterion and generates an optimal policy faster then both policy and
value iteration algorithms.
</div><br>

<A href="r42a-mdp_report.ps">
<img align=left border="0" src="/~dechter/images/down.gif">&nbsp;&nbsp;<b>[ps] </b></a>
<A target=blank href="r42a-mdp_report.pdf">
<b>[pdf]</b></a>
</td></tr></table></center><br>

<!-- End Body-->

<!--- Begin Footer -->
     <div id="footer"><centeR>
<A HREF="http://www.ics.uci.edu">School of Information and Computer Science</A>
<A HREF="http://www.uci.edu">University of California, Irvine, CA 92697-3435</a>
<A HREF="http://www.ics.uci.edu/~dechter">Dr. Rina Dechter</A>

<A HREF="mailto:dechter_at_ics.uci.edu">dechter at ics.uci.edu</A>

</center></div>
<!--- End Footer -->

</body>
<html>

