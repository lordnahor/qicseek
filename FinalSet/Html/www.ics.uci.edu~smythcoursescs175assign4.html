<!DOCTYPE html PUBLIC "-//w3c//dtd html 4.0 transitional//en">
<html>
<head>
  <meta http-equiv="Content-Type"
 content="text/html; charset=iso-8859-1">
  <meta name="GENERATOR"
 content="Mozilla/4.76 [en] (WinNT; U) [Netscape]">
  <title>ICS 175: Project in Artificial Intelligence</title>
</head>
<body alink="#ff3300" bgcolor="#f3f9fe" link="#cc0000" text="#000000"
 vlink="#330099">
<center>
<h1>Assignment 4:&nbsp; CS 175: Project in Artificial Intelligence</h1>
</center>
<center>
<h2>Due at 9:30am Tuesday October 30th 2006</h2>
</center>
<hr>
<h3><big><big><font size="-1"><big><big>Instructions for Assignment 4</big></big></font></big></big></h3>
<big><font size="-1"><big>In this assignment you will begin to work
with images
of
faces and learn how to display them. You will use your knn classifier
from
Assignment 2 to classify faces into two classes. </big></font><font
 size="-1"><big>First
download the zip file <a href="assignment4.zip">assignment4.zip</a> which contains both
MATLAB .m functions and MATLAB .mat files containing images.</big></font></big>
<h4><big><big><font size="-1"><big><big>Part 1: Displaying A Face Image</big></big></font></big></big></h4>
<p><big><font size="-1"><big>First type "load singleface" to load into
MATLAB
an&nbsp;
image of a single face stored in the MATLAB file singleface.mat.This is
a single monochrome image as we have discussed in class.You can display
this (or any other image) using the dispimg.m function which is among
the
MATLAB files you downloaded. The dispimg.m function takes as input an
image,
performs some simple scaling (calling the scale.m function), defines
the
colormap gray, and then displays the image. Try modifying this function
so that it uses a different colormap (type "help colormap" to find out
what colormaps are available) and see the effect. (You can change back
the function to a grayscale when you are done).</big></font>
</big></p>
<p><big><font size="-1"><big>Find the maximum, minimum, median, mean,
and standard
deviation
of the pixel intensities in the image. Plot a histogram of the pixel
intensities
and comment on what it tells you about the image (use the "hist"
function).
Keep in mind that all of these functions operate on column vectors: so
you will need to reshape your image matrix as a column vector first
(use
"reshape.m").</big></font>
</big></p>
<p><big><font size="-1"><big>Now write a simple&nbsp; function which
will
threshold this image to
create a new image such that all pixels in the original image which
are brighter than the threshold t are mapped to 1 and all pixels with
intensities less than or equal to t are mapped to value 0.</big></font>
</big></p>
<ul>
  <big> <font size="-1"><big>&nbsp;function [timage] =
threshold_image(image, t)</big></font> <br>
  <font size="-1"><big>&nbsp;% function [timage] =
threshold_image(image, t)</big></font> <br>
  <font size="-1"><big>&nbsp; %</big></font> <br>
  <font size="-1"><big>&nbsp; %&nbsp; a brief description of what the
function
does</big></font> <br>
  <font size="-1"><big>&nbsp; %&nbsp; ......</big></font> <br>
  <font size="-1"><big>&nbsp;
%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
Your Name, CS 175, date</big></font> <br>
  <font size="-1"><big>&nbsp; %</big></font> <br>
  <font size="-1"><big>&nbsp; %&nbsp; Inputs</big></font> <br>
  <font size="-1"><big>&nbsp; %&nbsp;&nbsp;&nbsp;&nbsp; image: a M x
N&nbsp;
matrix of pixel intensities</big></font> <br>
  <font size="-1"><big>&nbsp; %&nbsp;&nbsp;&nbsp;&nbsp; t:&nbsp; a
scalar,
the intensity threshold.</big></font> <br>
  <font size="-1"><big>&nbsp; %</big></font> <br>
  <font size="-1"><big>&nbsp; %&nbsp; Outputs</big></font> <br>
  <font size="-1"><big>&nbsp; %&nbsp;&nbsp;&nbsp;&nbsp; timage: a M x N
matrix
of thresholded pixel intensities</big></font> <br>
  <font size="-1"><big>&nbsp; %&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; where
intensities
above t are 1 and others are 0</big></font> </big>
  <p><big><font size="-1"><big>&nbsp;&nbsp;&nbsp; ----------------
your&nbsp;
code goes
here ------------------</big></font></big></p>
  <big></big>
</ul>
<big><font size="-1"><big>Display thresholded images for 3 different
values of t:
(1)
t = mean (average) pixel intensity of the original image, (2) t = 0.2,
(3)&nbsp; t=0.7. Briefly discuss the use of thresholding
as
a way to detect objects in images (e.g., what are the advantages and
what
are the potential limitations of this approach).</big></font>
<br>
&nbsp;
<br>
&nbsp;
<br>
&nbsp;
</big>
<h4><big><big><font size="-1"><big><big>Part 2: Displaying Sets of Faces</big></big></font></big></big></h4>
<big><font size="-1"><big>Now load the files i2up.mat and
i2straight.mat into
MATLAB, and you will get two arrays of data structures of size 20 x 4,
one called i2up and one called i2straight.</big></font></big>
<p><big><font size="-1"><big>&raquo; i2up</big></font>
<br>
<font size="-1"><big>i2up =</big></font>
<br>
<font size="-1"><big>20x4 struct array with fields:</big></font>
<br>
<font size="-1"><big>&nbsp;&nbsp;&nbsp; directory</big></font>
<br>
<font size="-1"><big>&nbsp;&nbsp;&nbsp; name</big></font>
<br>
<font size="-1"><big>&nbsp;&nbsp;&nbsp; image</big></font>
<br>
<font size="-1"><big>&nbsp;&nbsp;&nbsp; type</big></font>
</big></p>
<p><big><font size="-1"><big>This tells us that "i2up" is a structure
array of
dimension
20 by 4. Each element of this array has 4 fields. The first dimension
of
the structure varies from 1 to 20 and corresponds to 20 different
people.
The second dimension of the array, varying from 1 to 4, corresponds to
the specific type of&nbsp; expression (happy, sad, angry, neutral)
recorded
for each person. The field i2up.type is a string which records what the
name
of the image type is. You can ignore the directory field. The i2up.name
field
is a character string containing the name of the person.The i2up.image
field
is the actual image, a matrix of pixel values. These images are
relatively
low resolution so you will not be able to see the person's expression
very
clearly. Thus we have 20 people, and 4 images for each person, 80
images
in total. &nbsp;</big></font>
</big></p>
<p><big><font size="-1"><big>The "i2up" and the "i2straight" structure
have
exactly the
same people in exactly the same order, with the same expressions, but
in
"i2up" each person has their head at an upward angle, while in
"i2straight"
each person has their head at a "straight head-on" angle to the camera.</big></font>
</big></p>
<p><big><font size="-1"><big>First we can display individual images. If
we call
dispimg(i2straight(2,3).image)
we will display the image for the 2nd person using the 3rd expression,
in the "straight" angle to the camera.&nbsp; "i2straight(2,3).type"
will
tell us the type of expression for that image. These images are pretty
low resolution (about 60 x 60 pixels) so you can actually see the pixel
boundaries here. It is informative to grab the corner of the figure
window
and shrink the figure window on your screen - surprisingly you should
be
able to see the face "more clearly" as it shrinks. The pixel boundaries
distract our brain when they are visible, but when we shrink the figure
(and can't be distracted by the pixel boundaries) our brain can
recognize
more
structure in the image (typically more features of the&nbsp; face).</big></font>
</big></p>
<p><big><font size="-1"><big>Now we can display whole sets of images.
The
function
dispset2d.m is a simple MATLAB function which takes an array structure
of the form described above (e.g., "i2up") and displays a "mosaic"
of the individual images on an image grid. If you call
"dispset2d(i2straight(1,:));"
you will display all of the images for the first person on the list.
"dispset2d(i2straight(:,1));"
will display the first expression for each person on the list.&nbsp;
Note
also that this function lays out the mosaic column by column (i.e.,
columnwise
rather than row-wise, in the mosaic). Note that there may be some blank
images in the set: you will need to check that each image field
contains
data, i.e., that it is not just a null matrix.</big></font>
</big></p>
<p><big><font size="-1"><big>You are to write a MATLAB function which
will take a
structure
array of images (with exactly the same fields as above, e.g., "i2up"),
find
the k nearest neighbor images to a specified "query image", and display
both the original image and the k nearest neighbor images if "plotflag"
is 1 (the first image that shows up in the displayed result (top
leftmost image in the mosaic), and on the list of indices, should be
the query image itself). The query image is specified by input
arguments i and j, namely
the
(i,j)th element of the structure array. If you wish you can provide some additional visual information to identify the query image (the first image displayed), e.g., by automatically drawing a red box around the image or some other visual cue. <br>
</big></font></big></p>
<p><big><font size="-1"><big>The k nearest neighbor images
are
defined as the k images (including the query image itself) which
are
closest to this query image where "closeness" is measured by Euclidean
distance. Euclidean distance between two matrix images is defined the
same
way as for two vectors, i.e., pixel by pixel differences squared and
summed.
One way to do this is to convert the images to vectors and then just
call
your code from Assignment 2 for finding the k closest vectors to a
given
one. Or you can take the differences of 2 images directly by
subtracting the 2 matrices corresponding to the 2 images, and then
squaring the resulting differences, summing them up and taking the
square root of the sum. [Note, if you don't have working kNN code, or its too slow, feel free to use the code examples provided in slides in class - if that does not work, please feel free to email the TA or the instructor]. <br>
</big></font></big></p>
<p><big><font size="-1"><big>&nbsp;Finally, you need to call
dispset2d.m from within this function to
create your display (or adapt or replicate the necessary code from
within
dispset2d.m). To get this to work you may need to experiment a bit with
the
function
dispset2d.m.</big></font>
</big></p>
<p><big><font size="-1"><big>function&nbsp; [list] =
knndispset(imageset,i,j,k,plotflag)</big></font>
<br>
<font size="-1"><big>&nbsp; % function&nbsp; [list] =
knndispset(imageset,i,j,k, plotflag)</big></font>
<br>
<font size="-1"><big>&nbsp; %</big></font>
<br>
<font size="-1"><big>&nbsp; %&nbsp; a brief description of what the
function
does</big></font>
<br>
<font size="-1"><big>&nbsp; %&nbsp; ......</big></font>
<br>
<font size="-1"><big>&nbsp;
%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
Your Name, CS 175, date</big></font>
<br>
<font size="-1"><big>&nbsp; %</big></font>
<br>
<font size="-1"><big>&nbsp; %&nbsp; Inputs</big></font>
<br>
<font size="-1"><big>&nbsp; %&nbsp;&nbsp;&nbsp;&nbsp; imageset:&nbsp;
an
array
structure of images (CS 175 format)</big></font>
<br>
<font size="-1"><big>&nbsp; %&nbsp;&nbsp;&nbsp;&nbsp; i, j:&nbsp;
integers
specifying that imageset(i,j).image is the query image</big></font>
<br>
<font size="-1"><big>&nbsp; %&nbsp;&nbsp;&nbsp;&nbsp; k: number of
neighbors
to find</big></font>
<br>
<font size="-1"><big>&nbsp; %&nbsp;&nbsp;&nbsp; plotflag: display the k
nearest
neighbors if plotflag = 1;</big></font>
<br>
<font size="-1"><big>&nbsp; %</big></font>
<br>
<font size="-1"><big>&nbsp;%&nbsp; Outputs</big></font>
<br>
<font size="-1"><big>&nbsp;%&nbsp;&nbsp;&nbsp; list: a k x 2 matrix,
where
the first row contains the indices from imageset of the nearest
neighbor,</big></font>
<br>
<font size="-1"><big>%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
the second row contains the indices of the 2nd nearest neighbor, and so
forth.</big></font>
</big></p>
<p><big><font size="-1"><big>&nbsp;&nbsp;&nbsp; ----------------
your&nbsp; code
goes
here ------------------</big></font>
</big></p>
<p><big><font size="-1"><big>To test this code, you can print out the
indices
(i,j)
for each of the k neighbors that are found: for a query on individual
i,
you should find in almost all cases with this data that the 3 closest
neighbors
are also images from individual i.</big></font>
<br>
&nbsp;
<br>
&nbsp; <br>
</big></p>
<h4><big>Part 3: Comparing Classifiers using&nbsp; Cross-Validation</big></h4>
<big><font size="-1"><big>In this part of the assignment we are giving
you the
code that you will need and you just need to run the code as describe
below and generate a table of results.&nbsp; As discussed in class, the
training data accuracy
need
not be a good indicator of how a classifier will perform on new unseen
data. To estimate this "generalization accuracy" we can use the
technique
of cross-validation as discussed in class. You will use a function
called test_classifiers.m&nbsp;
that will calculate both the cross-validation accuracy and the training
accuracy for each of (a) a minimum distance classifier, and (b) K
different
knn classifiers, each using a different value of k (default value is K
= 1, with k = 1). <br>
<br>
The minimum distance classifier was
described in class and is called minimum_distance.m, and you can find
out how it is called by typing "help minimum_distance" in MATLAB.<br>
<br>
The code below calls the function knn.m as specified for Assignment 2,
with the same arguments - so you need to have a working version of
knn.m for the code below to run.</big></font><br>
<br>
</big><big><font size="-1"><big>The header for the function
test_classifiers is as
follows:<br>
<br>
<br>
</big></font></big><font size="-1"><big>function [cvacc, trainacc] =
test_classifiers(data1,data2,kvalues,v,rseed)</big></font>
<br>
</>
<big><font size="-1"><big>% function
test_classifiers(data1,data2,kvalues,v,rseed)</big></font>
<br>
<font size="-1"><big>%</big></font>&nbsp; <br>
.........<br>
<font size="-1"><big>%</big></font>
<br>
<font size="-1"><big>% INPUTS:</big></font>
<br>
<font size="-1"><big>%&nbsp;&nbsp; data1: n1 x d feature data for class
1</big></font>
<br>
<font size="-1"><big>%&nbsp;&nbsp; data2: n2 x d feature data for class
2</big></font>
<br>
<font size="-1"><big>%&nbsp;&nbsp; kvalues: a K x 1 vector of kvalues
for
knn</big></font>
<br>
<font size="-1"><big>%&nbsp;&nbsp; v: for "v-fold" cross-validation</big></font>
<br>
<font size="-1"><big>%&nbsp;&nbsp; rseed: state of random seed before
permuting
the data order</big></font>
<br>
<font size="-1"><big>%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (this is useful
for
debugging
since it allows us to repeat a given run exactly).</big></font>
<br>
<font size="-1"><big>%</big></font>
<br>
<font size="-1"><big>% OUTPUT:</big></font>
<br>
<font size="-1"><big>%&nbsp; cvacc: K+1 x 1 vector of accuracies
estimated
using cross-validation</big></font>
<br>
<font size="-1"><big>%&nbsp; trainacc: K+1 x 1 vector of accuracies on
the
training data</big></font>
<br>
<font size="-1"><big>%&nbsp;&nbsp;&nbsp; where:&nbsp; (1) accuracy is
expressed
as a percentage, between 0 and 100%</big></font>
<br>
<font size="-1"><big>%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
(2) K is the number of different k values used for knn (i.e.,
length(kvalues))</big></font>
<br>
<font size="-1"><big>%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
(3) cvacc(i), trainacc(i), for i=1:K, is the accuracy for knn with k =
kvalues(i)</big></font>
<br>
<font size="-1"><big>%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
(4) cvacc(K+1), trainacc(K+1), is the accuracy for the minimum distance
classifier</big></font></big>
<p><big><font size="-1"><big>As well as returning the specified results
above,
the code prints out the training accuracy and cross-validation
accuracy
for each example (to the screen) so that it is easy to see what is
going
on.</big></font>
</big></p>
<p><big><font size="-1"><big>As a simple test of this code, if you use
the data1 and
data2
data sets (data from each of the 2 classes that are in the .mat file
assignment4_simulated_data.mat), and call the
function with k=1 nearest-neighbors you should get approximately
the&nbsp; following
results (there may be differences in how the random number generator
works on different machines, so your cross-validation partitions might
be different to those used in the runs below, and consequentaly the
accuraries reported may be a little different - but they should be
roughly similar).<br>
</big></font><font size="-1"><big>&gt;&gt;
test_classifiers(data1,data2,1,10,1234);<br>
Training Data Results: <br>
Minimum distance accuracy = 74.00<br>
KNN, k=1, accuracy = 100.00<br>
<br>
Cross Validation Results (v=10): <br>
Minimum distance accuracy = 74.00<br>
KNN, k=1, accuracy = 67.00</big></font></big></p>
<p><big><font size="-1"><big><br>
If now try multiple different values for k, the
results
are
as follows:</big></font>
<br>
<font size="-1"><big>&gt;&gt; test_classifiers(data1,data2,[1 3 5 7 9
11 13 15 21 31 51],10,1234);<br>
Training Data Results: <br>
Minimum distance accuracy = 74.00<br>
KNN, k=1, accuracy = 100.00<br>
KNN, k=3, accuracy = 84.00<br>
KNN, k=5, accuracy = 83.50<br>
KNN, k=7, accuracy = 82.00<br>
KNN, k=9, accuracy = 81.50<br>
KNN, k=11, accuracy = 80.00<br>
KNN, k=13, accuracy = 80.50<br>
KNN, k=15, accuracy = 80.00<br>
KNN, k=21, accuracy = 79.00<br>
KNN, k=31, accuracy = 77.50<br>
KNN, k=51, accuracy = 76.50<br>
<br>
Cross Validation Results (v=10): <br>
Minimum distance accuracy = 74.00<br>
KNN, k=1, accuracy = 67.00<br>
KNN, k=3, accuracy = 76.00<br>
KNN, k=5, accuracy = 75.00<br>
KNN, k=7, accuracy = 78.00<br>
KNN, k=9, accuracy = 77.00<br>
KNN, k=11, accuracy = 76.00<br>
KNN, k=13, accuracy = 74.50<br>
KNN, k=15, accuracy = 75.50<br>
KNN, k=21, accuracy = 76.00<br>
KNN, k=31, accuracy = 75.50<br>
KNN, k=51, accuracy = 76.50</big></font></big></p>
<p><big><font size="-1"><big>Note that the results will be sensitive to
the
random
permutation of the data, i.e., different random permutations give
different
train/validation sets, and can give different accuracy estimates. Thus,
if you want to get the same results each time you run the code, you can
use the value rseed to reset the state of
the pseudorandom number generator.<br>
</big></font></big></p>
<p><big><font size="-1"><big>Important: you should verify that this
code is working (producing numbers similar or the same as those above
and running in reasonable time (certainly in less than a minute for the
example with multiple k values above)) before you proceed to Part 4
below.<br>
</big></font>&nbsp;
</big></p>
<h4><big>Part 4: Classifying&nbsp; Images</big></h4>
<big><font size="-1"><big>You will find in the MATLAB file
imagedata.mat the
following sets of images: (1)
rimages,
an array structure with 20 images (e.g., rimages(1).image) of faces
facing
to the right, where each image has been shrunk from its original 120 x
128 size to 30 x 32 (this was done to save on computation time), (2)
simages, same as rimages, but faces facing
straight
at the camera, (3) uimages, same as (1) but faces pointed upwards. You
are to write a general function (that uses the functions above) that
can
take any 2 sets of image structures (e.g., the right set and the
straight
set) and compare the performance (training accuracy and
cross-validation
accuracy) of the minimum distance classifier and the k-nearest-neighbor
classifier (as in Part 3, but you will now need to modify the
test_classifiers.m function so that it can handle image structures as
input). The function is defined below for you. </big></font></big>
<p><big><font size="-1"><big>Note: some of the images are blank. You
should not
use
these blank images for either training the classifier or testing the
classifier.&nbsp;
I suggest that you simply remove blank images when you do the image to
matrix conversion. Note that if you do *not* remove the blank images,
the
minimum distance classifier in particular will typically give much
worse
performance (the nearest neighbor classifier is not affected as much in
general): can you think why this would be the case for each of these 2
classifiers?&nbsp;</big></font>
</big></p>
<p><big><font size="-1"><big>function [cvacc, trainacc] =
test_imageclassifiers(imageset1,imageset2,plotflag,kvalues,v,rseed)</big></font>
<br>
<font size="-1"><big>% function&nbsp; [cvacc, trainacc] =
test_imageclassifiers(imageset1,imageset2,plotflag,kvalues,v,rseed)</big></font>
<br>
<font size="-1"><big>%</big></font>
<br>
<font size="-1"><big>% Learns a classifier to classify images in
imageset1</big></font>
<br>
<font size="-1"><big>% from images in imageset2, using minimum distance
and
knn classifiers,</big></font>
<br>
<font size="-1"><big>% and returns the training and cross-validation
accuracies.</big></font>
<br>
<font size="-1"><big>%</big></font>
<br>
<font size="-1"><big>%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
Your name, CS 175, date</big></font><br>
<font size="-1"><big>%</big></font>
<br>
<font size="-1"><big>% INPUTS:</big></font>
<br>
<font size="-1"><big>%&nbsp;&nbsp; imageset1, imageset2: arrays (of
size m
x n, and m2 x n2)</big></font>
<br>
<font size="-1"><big>%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; of
structures,
where imageset1(i,j).image is a matrix of</big></font>
<br>
<font size="-1"><big>%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; pixel
(image)
values
of size nx by ny. It is assumed</big></font>
<br>
<font size="-1"><big>%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; that all
images
are of the same size in both imageset1</big></font>
<br>
<font size="-1"><big>%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; and
imageset2.</big></font>
<br>
<font size="-1"><big>%&nbsp;&nbsp; plotflag: if plotflag=1, plot the
mean
image for each set,</big></font>
<br>
<font size="-1"><big>%&nbsp;&nbsp; and plot the difference of the means
of
the images in the two sets.</big></font>
<br>
<font size="-1"><big>%&nbsp;&nbsp; kvalues: an K x 1 vector of k values
for
the knn classifier</big></font>
<br>
<font size="-1"><big>%&nbsp;&nbsp; v: number of "folds" for v-fold
cross-validation</big></font>
<br>
<font size="-1"><big>%</big></font>
<br>
<font size="-1"><big>% OUTPUTS:</big></font>
<br>
<font size="-1"><big>%&nbsp; cvacc: K+1 x 1 vector of accuracies
estimated
using cross-validation</big></font>
<br>
<font size="-1"><big>%&nbsp; trainacc: K+1 x 1 vector of accuracies on
the
training data</big></font>
<br>
<font size="-1"><big>%&nbsp;&nbsp;&nbsp; where: (1) accuracy is
expressed
as a percentage, between 0 and 100%</big></font>
<br>
<font size="-1"><big>%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
(2) K is the number of different k values used for knn (i.e.,
length(kvalues))</big></font>
<br>
<font size="-1"><big>%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
(3) cvacc(i), trainacc(i), for i=1:K, is the accuracy for knn with k =
kvalues(i)</big></font>
<br>
<font size="-1"><big>%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
(4) cvacc(K+1, trainacc(K+1), is the accuracy for the minimum distance
classifier</big></font>
</big></p>
<p><big><font size="-1"><big>% convert each imageset to a feature
matrix form for
classification
learning</big></font>
<br>
<font size="-1"><big>dvector1 = image_to_matrix(imageset1);</big></font>
<br>
<font size="-1"><big>dvector2 = image_to_matrix(imageset2);</big></font>
</big></p>
<p><big><font size="-1"><big>% now run the various classifiers and
report the
accuracy
results</big></font>
<br>
<font size="-1"><big>[cvacc, trainacc] =
test_classifiers(dvector1,dvector2,kvalues,v,rseed);</big></font>
</big></p>
<p><big><font size="-1"><big>%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
------- end of MATLAB code --------------------</big></font>
<br>
&nbsp;
</big></p>
<p><big><font size="-1"><big>To help you test this function, here is an
example
of
the output produced by my function when called with these arguments.</big></font>
<br>
<font size="-1"><big>&gt;&gt;
test_imageclassifiers(rimages,simages,0,3,10,1234)</big></font>
</big></p>
<p><big><font size="-1"><big>Training Data Results:</big></font>
<br>
<font size="-1"><big>Minimum distance accuracy = 89.47</big></font>
<br>
<font size="-1"><big>KNN, k=3, accuracy = 84.21</big></font>
</big></p>
<big><font size="-1"><big>Cross Validation Results (v=10):</big></font>
<br>
<font size="-1"><big>Minimum distance accuracy = 86.67</big></font>
<br>
<font size="-1"><big>KNN, k=3, accuracy = 76.67<br>
<br>
Note: due to variability with the way the random number generator and
seeding works, the numbers you obtain may be slightly different, but
should nonetheless be in the 70 and 80 percent ranges.<br>
</big></font></big>
<p><big>&nbsp; &nbsp;
</big></p>
<hr>
<h3><big><font size="-1"><big>What to Turn In&nbsp; (EEE submission by
9:30am on Tuesday)<br>
</big></font></big></h3>
<ul>
  <big> </big><big> </big><li><big> <font size="-1"><big>(EEE) Part
1 of
your report&nbsp; in Word, containing
all
of the following. In your report <b>clearly</b> mark your name at the
top
of the report.</big></font></big></li>
  <big> </big>
  <ul>
    <big> </big><li><big> <font size="-1"><big>max, min, etc values
in Part 1, and a plot of
the
histogram.
Add some comments about your interpretation of the data.<br>
      </big></font></big></li>
    <big> </big><li><big> <font size="-1"><big>plots of the 3
thresholded images for Part 1,
again with comments.</big></font></big></li>
    <big> </big><li><big> <font size="-1"><big>plots of the displayed
mosaic images for Part
2
for the straight
data, (a) using (3,1) as the query image and k=3 and k=10, and (b)
using
(15,1) as the query image and k=3 and k=10. Again add comments on the
results.</big></font></big></li>
    <big> </big>
  </ul>
  <big> </big><li><big><font size="-1"><big>(EEE) Part 2 of your
report&nbsp; in Word, containing
all
of the following. &nbsp;</big></font></big></li>
  <big> </big>
  <ul>
    <big> </big><li><big><font size="-1"><big>IMPORTANT: use rseed =
1234 for all of the
experiments below
(feel free to conduct your own experiments
with
other seed values to investigate sensitivity of the results to
ordering:
the results will be sensitive since we are using relatively small
sample
sizes here).</big></font></big></li>
    <big> </big>
    <li><big><font size="-1"><big>A table with
cross-validation accuracies for
both (a) the
minimum distance and (b) the k-nearest neighbor classifier for k=1, 3,
5, 7, 9, (so 6 different classifiers in total) classifying "straight"
versus
"right" images. Add some commentary on your interpretation of the
classification
results, e.g.,comment on whether or not you think we have now
constructed
a good classifier for whether people's faces are up or down in general,
e.g., if we were to capture images of people in the CS 175 class with
a digital camera, of the same pixel size and roughly the same scale and
position relative to the camera, and feed them to the classifier.</big></font></big></li>
    <big> </big><li><big><font size="-1"><big>Repeat the last part for
"straight" versus "up"
images.</big></font></big></li>
    <big> </big><li><big><font size="-1"><big>Repeat the last part for
"up" versus "right"
images.</big></font></big></li>
    <big> </big><li><big><font size="-1"><big>OPTIONAL: you could find
all of the *errors*
that a specific
classifier makes and to display those as a mosaic, i.e., display the up
images
which
were confused as straight and vice-versa (note: this is purely optional
but is quite informative to do since it tells you what types of images
the classifier is making mistakes on and may suggest ideas for
improving
the classification performance, e.g., new features that might help. Or
it might show images that even a human would incorrectly label, i.e.,
where
the pixel information is inherently ambiguous).</big></font></big></li>
    <big> </big>
  </ul>
  <big> </big>
  <li><big> <font size="-1"><big>(EEE) Upload all your .m
files
(including any files from
earlier assignments that you need,
or other functions you wrote that you call for this assignment)to the EEE Assignment 4 drop box <br>
  </big></font></big></li>
  <li><big><font size="-1"><big>(Hardcopy) Turn in hardcopy of the
MATLAB
functions that you wrote for parts 1,2,3, and 4 of this assignment,
plus your Word file, by the end of class on Tuesday.&nbsp; Make sure
your name is clearly indicated on the front page of your hardcopy
submission.<br>
    </big></font></big></li>
  <big></big>
</ul>
</body>
</html>

